{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a864bd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "#from openai import OpenAI\n",
    "import PyPDF2\n",
    "import os\n",
    "openai.api_key = ''\n",
    "os.environ[\"OPENAI_API_KEY\"]=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff0d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating single file from multiple files \n",
    "import os \n",
    "file_list =  os.listdir('')\n",
    "def combine_data(file_list,path):\n",
    "    final_data = ''\n",
    "    for f in file_list:\n",
    "        with open(path+f'{f}',encoding=\"utf8\") as fp:\n",
    "            data = fp.read()\n",
    "            final_data = final_data+data  \n",
    "            final_data =  final_data + \"\\n\"\n",
    "    return final_data\n",
    "final_data  = combine_data(file_list,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60743045",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('combined_hr_data.txt', 'w',encoding=\"utf8\") as fp:\n",
    "    fp.write(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421ee0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def create_file_id(uploaded_file):\n",
    "        #First uploading the file\n",
    "        upload_file_object=client.files.create(\n",
    "        file=open(uploaded_file,\"rb\"),\n",
    "        purpose=\"assistants\"\n",
    "          )\n",
    "        print('The file object uploaded is :')\n",
    "        print(upload_file_object)\n",
    "        print('The id for the uploaded file is ',upload_file_object.id)\n",
    "        return upload_file_object.id\n",
    "\n",
    "#creating Assistant from the uploaded files\n",
    "def adding_file_to_assistant(list_file_id,name_assistant):\n",
    "        my_assistant = client.beta.assistants.create(\n",
    "        instructions=\"\",\n",
    "        name=name_assistant,\n",
    "        tools=[{\"type\": \"retrieval\"}],\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        file_ids=list_file_id\n",
    "        )\n",
    "        return (my_assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e9a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "def num_tokens_from_string(string: str, encoding_name: str):\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d31fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter,TokenTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "def create_splits_langchain(sample_data_path):\n",
    "    loader = TextLoader(sample_data_path,encoding=\"utf8\")\n",
    "    documents = loader.load()\n",
    "    doc_splitter_sample = TokenTextSplitter(\n",
    "        chunk_size = 1000000,\n",
    "        chunk_overlap  = 30000\n",
    "    )\n",
    "    texts_sample=doc_splitter_sample.split_documents(documents)\n",
    "    return texts_sample\n",
    "texts_sample = create_splits_langchain(\"combined_hr_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44371f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(token_)\n",
    "plt.xlabel('Number of Files')\n",
    "plt.ylabel('Number of Tokens in File')\n",
    "plt.title('Zakon HR Data splitting based on Tokens')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dedf474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading data to OpenAI\n",
    "assistant_file_list = []\n",
    "for e in range(0,len(texts_sample)):\n",
    "    with open (f'chunck_{e}.txt', 'w',encoding=\"utf8\") as fp:\n",
    "        fp.write(texts_sample[e].page_content)\n",
    "        file_name = f\"chunck_{e}.txt\"\n",
    "    file_id = create_file_id(file_name)\n",
    "    assistant_file_list.append(file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1613d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "total_files=client.files.list().data\n",
    "uploaded_file_name = [total_files[i].filename for i in range(len(total_files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7299ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id_sample_new_set = create_file_id('chunk_1.txt') #this would generate File ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987fa3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Seeing how many assistants are created on this OpenAI API\n",
    "from openai import OpenAI\n",
    "my_assistants = client.beta.assistants.list(\n",
    "    order=\"desc\",\n",
    "    limit=\"20\",\n",
    ")\n",
    "print(my_assistants.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb85c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "message=client.beta.threads.messages.create(\n",
    "    thread_id = thread.id,\n",
    "    role ='user',\n",
    "    content ='Question1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b2776",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=my_sample_assistant_work_law.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b50b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.retrieve(\n",
    "  thread_id=thread.id,\n",
    "  run_id=run.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e590dd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while client.beta.threads.runs.retrieve(thread_id=thread.id,run_id=run.id).status == 'in_progress':\n",
    "    print('waiting')\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da49f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8064678",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.data[0].content[0].text.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf2c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in reversed(messages.data):\n",
    "    print(message.role + \": \" + message.content[0].text.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
